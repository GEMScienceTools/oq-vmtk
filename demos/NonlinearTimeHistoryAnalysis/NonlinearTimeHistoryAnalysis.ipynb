{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64c5fb72-db28-4180-86a8-07ca0e023679",
   "metadata": {},
   "source": [
    "# Nonlinear Time-History on MDOF System\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This Jupyter Notebook provides a structured workflow for performing a nonlinear time-history analyses (NLTHA) on multi-degree-of-freedom (MDOF) stick-and-mass structural models using a single record. By combining functions for MDOF modeling and dynamic analysis, the notebook enables the setup, execution, and post-processing of structural responses under earthquake loading.\n",
    "\n",
    "The main goals of this notebook:\n",
    "\n",
    "1. **Compile and construct MDOF Models in OpenSees**: Define and assemble MDOF models by specifying essential structural properties, including mass, heights and nonlinear response characteristics at each degree of freedom\n",
    "\n",
    "2. **Run Nonlinear Time-History Analysis (NLTHA) in OpenSees**: Simulate the dynamic response of MDOF structures under time-dependent inputs, such as ground motion records, to realistically assess structural behavior and response metrics (e.g., peak storey drifts, peak floor accelerations) under loading conditions and extract critical response metrics and model information.\n",
    "\n",
    "3. **Export Response Quantities from NLTHA**: Postprocess response quantities from NLTHA in a ready-to-use format by other OQ-VMTK modules and functions\n",
    "\n",
    "4. **Visualise Seismic Demands from NLTHA**: Visualise the seismic demand profiles (i.e., the distribution of peak storey drift and peak floor acceleration values along the height of the idealised MDOF model)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a3487b-9409-420e-8623-b1a521a3a0c2",
   "metadata": {},
   "source": [
    "## Initialize Libraries ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93e9dd2-9ed0-430f-9c12-2be3f3908292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import the classes necessary for structural analysis\n",
    "from openquake.vmtk.units         import units              # oq-vtmk units class\n",
    "from openquake.vmtk.modeller      import modeller           # oq-vmtk numerical modelling class\n",
    "from openquake.vmtk.plotter       import plotter            # oq-vmtk plotting class\n",
    "from openquake.vmtk.utilities     import export_to_pkl      # oq-vmtk utilities class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1054683-d8b7-4110-8ec5-5a0a2d0da11a",
   "metadata": {},
   "source": [
    "## Define Directories ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94d49ea-44b5-4bbe-98bd-f5e15abfa785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory of the ground-motion records\n",
    "gm_directory  = './records'            \n",
    "\n",
    "# Define the main output directory\n",
    "nrha_directory = './output'  \n",
    "os.makedirs(nrha_directory, exist_ok=True)\n",
    "\n",
    "# Define directory for temporary analysis outputs: it is used to store temporary .txt files used as accelerations recorders\n",
    "temp_nrha_directory = os.path.join(nrha_directory,'temp')\n",
    "os.makedirs(temp_nrha_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ae2a14-a644-46bf-b270-fdf67eedd8aa",
   "metadata": {},
   "source": [
    "## Required MDOF Modelling Input Parameters ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b07b3ef-e388-4917-9526-8b6d14fedab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of storeys\n",
    "number_storeys = 3 \n",
    "\n",
    "# Relative floor heights list\n",
    "floor_heights = [2.80, 3.00, 3.00]\n",
    "\n",
    "# Relative floor masses list\n",
    "floor_masses = [0.75, 0.75, 0.75] # Unit mass for SDOFs\n",
    "\n",
    "# SDOF capacity (First row are Spectral Displacement [m] values - Second row are Spectral Acceleration [g] values)\n",
    "# 3 storeys Ã— 4 points each\n",
    "storey_disps = np.array([\n",
    "    [0.005, 0.010, 0.020, 0.030],   # storey 1\n",
    "    [0.006, 0.012, 0.025, 0.035],   # storey 2\n",
    "    [0.007, 0.014, 0.030, 0.040]    # storey 3\n",
    "])\n",
    "\n",
    "storey_forces = np.array([\n",
    "    [100, 200, 150, 120],  # storey 1\n",
    "    [120, 240, 180, 140],  # storey 2\n",
    "    [140, 280, 200, 160]   # storey 3\n",
    "]) * units.kN   # or *units.g depending on definition\n",
    "\n",
    "# Flag to activate default stiffness-strength degradation and pinching4\n",
    "mdof_degradation = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14aa838b-dbc0-4a4d-825e-32977d40bf6b",
   "metadata": {},
   "source": [
    "## Setting Up, Running NLTHA and Exporting Analysis ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d458a5-8eec-4aeb-b0bc-aaa5c37ea84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise MDOF storage lists\n",
    "conv_index_list = []               # List for convergence indices\n",
    "peak_disp_list  = []               # List for peak floor displacement (returns all peak values along the building height)\n",
    "peak_drift_list = []               # List for peak storey drift (returns all peak values along the building height)\n",
    "peak_accel_list = []               # List for peak floor acceleration (returns all peak values along the building height)\n",
    "max_peak_drift_list = []           # List for maximum peak storey drift (returns the maximum value) \n",
    "max_peak_drift_dir_list = []       # List for maximum peak storey drift directions\n",
    "max_peak_drift_loc_list = []       # List for maximum peak storey drift locations\n",
    "max_peak_accel_list = []           # List for maximum peak floor acceleration (returns the maximum value)\n",
    "max_peak_accel_dir_list = []       # List for maximum peak floor acceleration directions \n",
    "max_peak_accel_loc_list = []       # List for maximum peak floor acceleration locations\n",
    "\n",
    "### Compile the MDOF model    \n",
    "model = modeller(number_storeys,\n",
    "                 floor_heights,\n",
    "                 floor_masses,\n",
    "                 storey_disps,\n",
    "                 storey_forces*units.g,\n",
    "                 mdof_degradation)                                                                # Initialise the class (Build the model)\n",
    "\n",
    "model.compile_model()                                                                             # Compile the MDOF model\n",
    "\n",
    "model.plot_model()                                                                                # Visualise the model (only on first iteration)        \n",
    "model.do_gravity_analysis()                                                                       # Do gravity analysis\n",
    "\n",
    "num_modes = 3\n",
    "T, phi = model.do_modal_analysis(num_modes = num_modes)                                           # Do modal analysis and get period of vibration (Essential step for running NLTHA)\n",
    "\n",
    "### Define ground motion objects\n",
    "fnames = [os.path.join(gm_directory,'acc.csv')]                                           # Ground-motion record names\n",
    "fdts   =  os.path.join(gm_directory,'dts.csv')                                            # Ground-motion time-step names \n",
    "dt_gm = pd.read_csv(fdts, header=None)[pd.read_csv(fdts,header=None).columns[0]].loc[1]-\\\n",
    "        pd.read_csv(fdts, header=None)[pd.read_csv(fdts,header=None).columns[0]].loc[0]           # Ground-motion time-step\n",
    "t_max = pd.read_csv(fdts)[pd.read_csv(fdts).columns[0]].iloc[-1]                                  # Ground-motion duration\n",
    "    \n",
    "### Define analysis params and do NLTHA\n",
    "dt_ansys = dt_gm                                                            # Set the analysis time-step\n",
    "sf = units.g                                                                # Set the scaling factor (if records are in g, a scaling factor of 9.81 m/s2 must be used to be consistent with opensees) \n",
    "control_nodes, conv_index, peak_drift, peak_accel, max_peak_drift, max_peak_drift_dir, max_peak_drift_loc, max_peak_accel, max_peak_accel_dir, max_peak_accel_loc, peak_disp = model.do_nrha_analysis(fnames, \n",
    "                                                                                                                                                                                                      dt_gm, \n",
    "                                                                                                                                                                                                      sf, \n",
    "                                                                                                                                                                                                      t_max, \n",
    "                                                                                                                                                                                                      dt_ansys,\n",
    "                                                                                                                                                                                                      temp_nrha_directory,\n",
    "                                                                                                                                                                                                      pflag=False,\n",
    "                                                                                                                                                                                                      xi = 0.05)\n",
    "\n",
    "print('Peak drift values in X-direction:', peak_drift[:,0], 'rad') # Peak drift values in the X-direction\n",
    "print('Peak drift values in Y-direction:', peak_drift[:,1], 'rad') # Peak drift values in the Y-direction (Zeros due to uni-directional loading)\n",
    "print('Peak acceleration values in X-direction:', [x/9.81 for x in peak_accel[:,0]], 'g') # Peak acceleration values in the X-direction (converted to g)\n",
    "print('Peak acceleration values in Y-direction:', [x/9.81 for x in peak_accel[:,1]], 'g') # Peak acceleration values in the Y-direction (converted to g)\n",
    "print('Maximum peak storey drift value of', max_peak_drift, 'encountered in', max_peak_drift_dir ,'direction', 'on storey #', max_peak_drift_loc)       # Reporting\n",
    "print('Maximum peak floor acceleration value of', max_peak_accel/9.81, 'encountered in', max_peak_accel_dir ,'direction', 'on storey #', max_peak_accel_loc) # Reporting\n",
    "\n",
    "### Store the analysis\n",
    "conv_index_list.append(conv_index)\n",
    "peak_drift_list.append(peak_drift)\n",
    "peak_accel_list.append(peak_accel)\n",
    "peak_disp_list.append(peak_disp)\n",
    "max_peak_drift_list.append(max_peak_drift)\n",
    "max_peak_drift_dir_list.append(max_peak_drift_dir)\n",
    "max_peak_drift_loc_list.append(max_peak_drift_loc)\n",
    "max_peak_accel_list.append(max_peak_accel)\n",
    "max_peak_accel_dir_list.append(max_peak_accel_dir)\n",
    "max_peak_accel_loc_list.append(max_peak_accel_loc)\n",
    "\n",
    "# Store the analysis results in a dictionary compatible with required input from other OQ-VMTK modules and functions\n",
    "ansys_dict = {}\n",
    "labels = ['T','control_nodes', 'conv_index_list',\n",
    "          'peak_drift_list','peak_accel_list',\n",
    "          'max_peak_drift_list', 'max_peak_drift_dir_list', \n",
    "          'max_peak_drift_loc_list','max_peak_accel_list',\n",
    "          'max_peak_accel_dir_list','max_peak_accel_loc_list',\n",
    "          'peak_disp_list']\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    ansys_dict[label] = vars()[f'{label}']\n",
    "# Export the analysis output variable to a pickle file using the \"export_to_pkl\" function from \"utilities\"\n",
    "export_to_pkl(os.path.join(nrha_directory,'ansys_out.pkl'), ansys_dict) \n",
    "\n",
    "print('ANALYSIS COMPLETED!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5187fd2b-1195-439f-b5e1-3f16422f0bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the plotter class\n",
    "pl = plotter()\n",
    "\n",
    "## Visualise the seismic demands\n",
    "pl.plot_demand_profiles(ansys_dict['peak_drift_list'], \n",
    "                        ansys_dict['peak_accel_list'], \n",
    "                        ansys_dict['control_nodes'], \n",
    "                        output_directory = None,\n",
    "                        plot_label=\"seismic_demand_profiles\") # The y-axis values of drift and acceleration are converted to % and g automatically by the plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75464b2-2474-45d7-b2ed-da77d4ff9169",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
