{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84601f95-76e2-433b-8cf7-a1a1a53e7599",
   "metadata": {},
   "source": [
    "# Example 2: Nonlinear Time-History Analysis of MDOF Systems using the \"modeller\" Class\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This Jupyter Notebook provides a structured workflow for performing nonlinear time-history analyses (NLTHA) on multi-degree-of-freedom (MDOF) structural models. By combining functions for MDOF modeling and dynamic analysis, the notebook enables the setup, execution, and post-processing of structural responses under earthquake loading.\n",
    "\n",
    "The main goals of this notebook:\n",
    "\n",
    "1. **Calibrate MDOF models based on single-degree-of-freedom (SDOF) oscillator capacity**: Calibrate storey-based force-deformation relationships using SDOF capacity curve definition (spectral displacement-spectral acceleration) based on the methodology of Lu et al. (2020) and other modifications to account for distinct response typologies (i.e., bilinear, trilinear and quadrilinear backbone definitions)\n",
    "\n",
    "2. **Compile and construct MDOF Models in OpenSees**: Define and assemble MDOF models by specifying essential structural properties, including:\n",
    "   - Mass, heights, fundamental period, etc.\n",
    "   - Nonlinear response characteristics at each degree of freedom\n",
    "\n",
    "3. **Run Nonlinear Time-History Analysis (NLTHA) in OpenSees**: Simulate the dynamic response of MDOF structures under time-dependent inputs, such as ground motion records, to realistically assess structural behavior and response metrics (e.g., peak storey drifts, peak floor accelerations) under loading conditions and extract critical response metrics and model information.\n",
    "\n",
    "The notebook provides a step-by-step guide, covering each phase from MDOF model calibration, setup to input parameter configuration, analysis execution, and detailed results extraction. Users should have some familiarity with python scripts, structural dynamics and computational modeling to fully benefit from this material.\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "To run this notebook successfully, the following \"non-native\" Python packages are required:\n",
    "-  openseespy: A Python library for performing finite element analysis based on the OpenSees framework.\n",
    "    - Reference: https://openseespydoc.readthedocs.io/en/latest/\n",
    "\n",
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "[1] Lu X, McKenna F, Cheng Q, Xu Z, Zeng X, Mahin SA. An open-source framework for regional earthquake loss estimation using the city-scale nonlinear time history analysis. Earthquake Spectra. 2020;36(2):806-831. doi:10.1177/8755293019891724"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fe0791-ba54-469e-b23b-38bf6a7d19ec",
   "metadata": {},
   "source": [
    "## Initialize Libraries ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7fbfbf-e29a-4403-983f-932d528c6a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Set paths\n",
    "vmtk = os.path.abspath(os.path.join(\"..\",\"..\"))\n",
    "sys.path.append(vmtk)\n",
    "os.chdir(os.path.join(vmtk,'src'))\n",
    "\n",
    "# Import the classes necessary for structural analysis\n",
    "from src.calibration import calibrate_model\n",
    "from src.modeller    import modeller\n",
    "from src.utilities   import sorted_alphanumeric, import_from_pkl, export_to_pkl\n",
    "from src.units       import units"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea65b575-ea8c-4935-bce9-8ee00e4cdae4",
   "metadata": {},
   "source": [
    "## Define Plotting Constants ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7af01b8-1bbb-4392-a2c4-8402c2227b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "FONTSIZE_1 = 16\n",
    "FONTSIZE_2 = 14\n",
    "FONTSIZE_3 = 12\n",
    "\n",
    "LINEWIDTH_1= 3\n",
    "LINEWIDTH_2= 2\n",
    "LINEWIDTH_3 = 1\n",
    "\n",
    "RESOLUTION = 500\n",
    "\n",
    "MARKER_SIZE_1 = 100\n",
    "MARKER_SIZE_2 = 60\n",
    "MARKER_SIZE_3 = 10\n",
    "\n",
    "COLOR = \"#399283\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab6e61e-8edb-4e5a-915c-27a65878a4a4",
   "metadata": {},
   "source": [
    "## Define Directories ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe84f5e-5552-4806-90b3-ae4f20a60667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory of the capacities\n",
    "capacity_directory = f'{vmtk}/demos/in/capacity'          \n",
    "\n",
    "# Define the directory of the ground-motion records\n",
    "gm_directory  = f'{vmtk}/demos/in/records'            \n",
    "\n",
    "# Define the main output directory\n",
    "nltha_directory = f'{vmtk}/demos/out/nltha'  \n",
    "if not os.path.exists(f'{nltha_directory}'):\n",
    "    os.makedirs(f'{nltha_directory}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c565bb-901c-4317-907a-9fddbea06314",
   "metadata": {},
   "source": [
    "## Required Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29b221a-5762-4279-8c9c-39e3d954c163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of storeys\n",
    "number_storeys = 2\n",
    "# Relative floor heights list\n",
    "floor_heights = [2.80, 2.80]\n",
    "# First-mode based participation factor\n",
    "gamma = 1.33\n",
    "# SDOF capacity (First row are Spectral Displacement [m] values - Second row are Spectral Acceleration [g] values)\n",
    "sdof_capacity = np.array([[0.00060789, 0.00486316, 0.02420000, 0.04353684], \n",
    "                          [0.10315200, 0.20630401, 0.12378241, 0.12502023]]).T\n",
    "# SDOF period\n",
    "sdof_period = 0.154\n",
    "# Frame flag\n",
    "isFrame = False\n",
    "# Soft-storey mechanism flag\n",
    "isSOS = False\n",
    "# Degradation\n",
    "mdof_degradation = True\n",
    "# Inherent damping \n",
    "mdof_damping = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d9e222-c952-4e9f-b68b-7d23422395ff",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465c4236-a877-4dcc-b498-5cda9a895c69",
   "metadata": {},
   "source": [
    "## Analysis Part 1: Calibrate MDOF Model based on SDOF Capacity Definition ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86200687-ccbf-4df0-bde2-7c4b3d20fbf1",
   "metadata": {},
   "source": [
    "#### The calibration function (calibrate_model) requires six input arguments:\n",
    "1. Number of storeys\n",
    "2. First-mode transformation factor (gamma)\n",
    "3. The capacity array of the single degree-of-freedom oscillator\n",
    "4. The fundamental period of the single degree-of-freedom oscillator\n",
    "5. Boolean flag whether the lateral load-resisting system for the considered building class is moment-resisting frames (or not)\n",
    "6. Boolean flag whether the building class expects a soft-storey mechanism to be activated (or not)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f37bde-c84e-40bd-8050-6c414d4c17c7",
   "metadata": {},
   "source": [
    "#### The calibration function (calibrate_model) returns four output variables:\n",
    "1. The floor mass array to be assigned to the MDOF model generator (floor_masses)\n",
    "2. The storey deformation (in m) capacity to be assigned to the MDOF model generator (storey_disps)\n",
    "3. The acceleration capacity (in g) to be assigned to the MDOF model generator (storey_forces)\n",
    "4. The considered mode shape (mdof_phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2098220-a7f0-4f5f-b369-f7adb4c759c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibrate the model using the Lu et al. (2020) method\n",
    "floor_masses, storey_disps, storey_forces, mdof_phi = calibrate_model(number_storeys, gamma, sdof_capacity, sdof_period, isFrame, isSOS)\n",
    "\n",
    "print('The mass of each floor (in tonnes):', floor_masses)\n",
    "print('The first-mode shape used for calibration:', mdof_phi)\n",
    "\n",
    "# Plot the capacities to visualise the outcome of the calibration\n",
    "for i in range(storey_disps.shape[0]):\n",
    "   plt.plot(np.concatenate(([0.0], storey_disps[i,:])), np.concatenate(([0.0], storey_forces[i,:]*9.81)), label = f'Storey #{i+1}')\n",
    "plt.plot(np.concatenate(([0.0], sdof_capacity[:,0])), np.concatenate(([0.0], sdof_capacity[:,1]*9.81)), label = f'SDOF Capacity')\n",
    "plt.xlabel('Storey Deformation [m]', fontsize= FONTSIZE_1)\n",
    "plt.ylabel('Storey Shear [kN]', fontsize = FONTSIZE_1)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.grid(visible=True, which='major')\n",
    "plt.grid(visible=True, which='minor')\n",
    "plt.xlim([0.00, 0.03])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26249fb-95f2-4d77-8ad7-d2fd38fc02f5",
   "metadata": {},
   "source": [
    "## Analysis Part 2: Setting Up Analysis and Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5bb079-a45c-4c96-b6da-ee01e6c7d168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise MDOF storage lists\n",
    "mdof_coll_index_list = []               # List for collapse index\n",
    "mdof_peak_disp_list  = []               # List for peak floor displacement (returns all peak values along the building height)\n",
    "mdof_peak_drift_list = []               # List for peak storey drift (returns all peak values along the building height)\n",
    "mdof_peak_accel_list = []               # List for peak floor acceleration (returns all peak values along the building height)\n",
    "mdof_max_peak_drift_list = []           # List for maximum peak storey drift (returns the maximum value) \n",
    "mdof_max_peak_drift_dir_list = []       # List for maximum peak storey drift directions\n",
    "mdof_max_peak_drift_loc_list = []       # List for maximum peak storey drift locations\n",
    "mdof_max_peak_accel_list = []           # List for maximum peak floor acceleration (returns the maximum value)\n",
    "mdof_max_peak_accel_dir_list = []       # List for maximum peak floor acceleration directions \n",
    "mdof_max_peak_accel_loc_list = []       # List for maximum peak floor acceleration locations \n",
    "\n",
    "# Define directory for temporary analysis outputs\n",
    "temp_nrha_outdir = f'{nltha_directory}/temp'\n",
    "if not os.path.exists(f'{temp_nrha_outdir}'):\n",
    "    os.makedirs(f'{temp_nrha_outdir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0790ae3d-e95c-46f8-8ccc-a2aee02444b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over ground-motion records, compile MDOF model and run NLTHA\n",
    "gmrs = sorted_alphanumeric(os.listdir(f'{gm_directory}/acc'))                         # Sort the ground-motion records alphanumerically\n",
    "dts  = sorted_alphanumeric(os.listdir(f'{gm_directory}/dts'))                         # Sort the ground-motion time-step files alphanumerically\n",
    "\n",
    "for i in range(len(gmrs)):\n",
    "    ### Print post-processing iteration\n",
    "    print('================================================================')\n",
    "    print('============== ANALYSING: {:d} out of {:d} =================='.format(i+1, len(gmrs)))\n",
    "    print('================================================================')\n",
    "\n",
    "    ### Compile the MDOF model    \n",
    "    model = modeller(number_storeys,\n",
    "                     floor_heights,\n",
    "                     floor_masses,\n",
    "                     storey_disps,\n",
    "                     storey_forces*units.g,\n",
    "                     mdof_degradation)                                                                # Initialise the class (Build the model)\n",
    "    \n",
    "    model.compile_model()                                                                             # Compile the MDOF model\n",
    "    \n",
    "    if i==0:\n",
    "        model.plot_model()                                                                            # Visualise the model (only on first iteration)\n",
    "        \n",
    "    model.do_gravity_analysis()                                                                       # Do gravity analysis\n",
    "\n",
    "    if number_storeys == 1:\n",
    "        num_modes = 1\n",
    "    else:\n",
    "        num_modes = 3\n",
    "    T, _ = model.do_modal_analysis(num_modes = num_modes)                                             # Do modal analysis and get period of vibration\n",
    "\n",
    "    ### Define ground motion objects\n",
    "    fnames = [f'{gm_directory}/acc/{gmrs[i]}']                                                        # Ground-motion record names\n",
    "    fdts   =  f'{gm_directory}/dts/{dts[i]}'                                                          # Ground-motion time-step names \n",
    "    dt_gm = pd.read_csv(fdts, header=None)[pd.read_csv(fdts,header=None).columns[0]].loc[1]-\\\n",
    "            pd.read_csv(fdts, header=None)[pd.read_csv(fdts,header=None).columns[0]].loc[0]           # Ground-motion time-step\n",
    "    t_max = pd.read_csv(fdts)[pd.read_csv(fdts).columns[0]].iloc[-1]                                  # Ground-motion duration\n",
    "    \n",
    "    ### Define analysis params and do NLTHA\n",
    "    dt_ansys = dt_gm                                                            # Set the analysis time-step\n",
    "    sf = units.g                                                                # Set the scaling factor (if records are in g, a scaling factor of 9.81 m/s2 must be used to be consistent with opensees) \n",
    "    control_nodes, coll_index, peak_drift, peak_accel, max_peak_drift, max_peak_drift_dir, max_peak_drift_loc, max_peak_accel, max_peak_accel_dir, max_peak_accel_loc, peak_disp = model.do_nrha_analysis(fnames, \n",
    "                                                                                                                                                                                                          dt_gm, \n",
    "                                                                                                                                                                                                          sf, \n",
    "                                                                                                                                                                                                          t_max, \n",
    "                                                                                                                                                                                                          dt_ansys,\n",
    "                                                                                                                                                                                                          temp_nrha_outdir,\n",
    "                                                                                                                                                                                                          pflag=False,\n",
    "                                                                                                                                                                                                          xi = mdof_damping)\n",
    "\n",
    "    ### Store the analysis\n",
    "    mdof_coll_index_list.append(coll_index)\n",
    "    mdof_peak_drift_list.append(peak_drift)\n",
    "    mdof_peak_accel_list.append(peak_accel)\n",
    "    mdof_peak_disp_list.append(peak_disp)\n",
    "    mdof_max_peak_drift_list.append(max_peak_drift)\n",
    "    mdof_max_peak_drift_dir_list.append(max_peak_drift_dir)\n",
    "    mdof_max_peak_drift_loc_list.append(max_peak_drift_loc)\n",
    "    mdof_max_peak_accel_list.append(max_peak_accel)\n",
    "    mdof_max_peak_accel_dir_list.append(max_peak_accel_dir)\n",
    "    mdof_max_peak_accel_loc_list.append(max_peak_accel_loc)\n",
    "\n",
    "print('ANALYSIS COMPLETED')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb7370a-a06c-4390-ad5a-f3cdbf0a474e",
   "metadata": {},
   "source": [
    "## Analysis Part 3: Export The Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1581cba7-e25e-4614-8678-cdbd03123ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the analysis results in a dictionary\n",
    "ansys_dict = {}\n",
    "labels = ['T','control_nodes', 'mdof_coll_index_list',\n",
    "          'mdof_peak_drift_list','mdof_peak_accel_list',\n",
    "          'mdof_max_peak_drift_list', 'mdof_max_peak_drift_dir_list', \n",
    "          'mdof_max_peak_drift_loc_list','mdof_max_peak_accel_list',\n",
    "          'mdof_max_peak_accel_dir_list','mdof_max_peak_accel_loc_list',\n",
    "          'mdof_peak_disp_list']\n",
    "for i, label in enumerate(labels):\n",
    "    ansys_dict[label] = vars()[f'{label}']\n",
    "# Export the analysis output variable to a pickle file using the \"export_to_pkl\" function from \"utilities\"\n",
    "export_to_pkl(f'{nltha_directory}/ansys_out.pkl', ansys_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c597d643-c4a5-4794-85e7-f3bc29094f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()\n",
    "print('Elapsed Time:', (end - start)/60, 'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca99f93-fd56-4abc-9b17-3a378b258f03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
