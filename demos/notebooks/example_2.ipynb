{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84601f95-76e2-433b-8cf7-a1a1a53e7599",
   "metadata": {},
   "source": [
    "# Example 2: Nonlinear Time-History Analysis of MDOF Systems using the \"modeller\" Class\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This Jupyter Notebook provides a structured workflow for performing nonlinear time-history analyses (NLTHA) on multi-degree-of-freedom (MDOF) structural models. By combining functions for MDOF modeling and dynamic analysis, the notebook enables the setup, execution, and post-processing of structural responses under earthquake loading.\n",
    "\n",
    "The key objectives of this notebook are:\n",
    "\n",
    "1. **SDoF-to-MDoF Model Calibration**: Calibrate storey-based force-deformation relationships using SDoF capacity curve definition (spectral displacement-spectral acceleration) based on the methodology of Lu et al. (2020) and other modifications to account for distinct response typologies (i.e., bilinear, trilinear and quadrilinear backbone definitions)\n",
    "\n",
    "2. **MDOF Model Construction**: Define and assemble MDOF models by specifying essential structural properties, including:\n",
    "   - Mass, heights, fundamental period, etc.\n",
    "   - Nonlinear response characteristics at each degree of freedom\n",
    "\n",
    "3. **Nonlinear Time-History Analysis (NLTHA)**: Simulate the dynamic response of MDOF structures under time-dependent inputs, such as ground motion records, to realistically assess structural behavior and response metrics (e.g., peak storey drifts, peak floor accelerations) under loading conditions and extract critical response metrics and model information.\n",
    "\n",
    "The notebook provides a step-by-step guide, covering each phase from MDOF model calibration, setup to input parameter configuration, analysis execution, and detailed results extraction. Users should have some familiarity with python scripts, structural dynamics and computational modeling to fully benefit from this material.\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "To run this notebook successfully, the following \"non-native\" Python packages are required:\n",
    "-  openseespy: A Python library for performing finite element analysis based on the OpenSees framework.\n",
    "    - Reference: https://openseespydoc.readthedocs.io/en/latest/\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Workflow Overview\n",
    "\n",
    "1. **Input Parameters** \n",
    "2. **Initialize Libraries and Modules**: Load essential libraries and custom functions for MDOF modeling.\n",
    "3. **Define Directories**: Assign and create directories to import and export data\n",
    "4. **Import Data**: Automatic import of necessary data\n",
    "4. **Define Structural Properties**: Set up mass, stiffness, damping, and nonlinear properties for each degree of freedom.\n",
    "5. **Execute Nonlinear THA**: Run the time-history analysis using dynamic loading inputs.\n",
    "6. **Post-Process and Visualize Results**: Generate plots and summaries to examine the structure’s response to the applied loading.\n",
    "\n",
    "By the end of this notebook, users will have a complete, adaptable script for nonlinear dynamic analyses on MDOF structures, supporting a range of investigation scenarios and performance assessments.\n",
    "\n",
    "Let’s begin by defining initial input parameters and loading the required libraries and setting up the initial parameters for the MDOF model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fe0791-ba54-469e-b23b-38bf6a7d19ec",
   "metadata": {},
   "source": [
    "# Initialize Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7fbfbf-e29a-4403-983f-932d528c6a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import os\n",
    "\n",
    "vulnerability_toolkit = os.path.abspath(os.path.join(\"..\",\"..\"))\n",
    "sys.path.append(vulnerability_toolkit)\n",
    "os.chdir(os.path.join(vulnerability_toolkit,'src'))\n",
    "\n",
    "from src.modeller import modeller\n",
    "from src.calibration import calibration\n",
    "from src.utilities import *\n",
    "from src.units import *\n",
    "\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab6e61e-8edb-4e5a-915c-27a65878a4a4",
   "metadata": {},
   "source": [
    "# Define Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe84f5e-5552-4806-90b3-ae4f20a60667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory of the capacities\n",
    "capDir= f'{vulnerability_toolkit}/example/in/capacity'          \n",
    "\n",
    "# Define the directory of the ground-motion records\n",
    "gmDir  = f'{vulnerability_toolkit}/example/in/records'            \n",
    "\n",
    "# Define the main output directory\n",
    "nlthaOutDir = f'{vulnerability_toolkit}/example/out/nltha'  \n",
    "if not os.path.exists(f'{nlthaOutDir}'):\n",
    "    os.makedirs(f'{nlthaOutDir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c565bb-901c-4317-907a-9fddbea06314",
   "metadata": {},
   "source": [
    "# Required Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29b221a-5762-4279-8c9c-39e3d954c163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of storeys\n",
    "number_storeys = 2\n",
    "# Relative floor heights list\n",
    "floor_heights = [2.80, 2.80]\n",
    "# First-mode based participation factor\n",
    "gamma = 1.33\n",
    "# SDOF capacity (Sd-Sa)\n",
    "sdof_capacity = np.array([[0.00060789, 0.00486316, 0.02420000, 0.04353684], \n",
    "                          [0.10315200, 0.20630401, 0.12378241, 0.12502023]]).T\n",
    "# SDOF period\n",
    "sdof_period = 0.154\n",
    "# Frame flag\n",
    "isFrame = False\n",
    "# Soft-storey mechanism flag\n",
    "isSOS = False\n",
    "# Inherent damping \n",
    "sdof_damping = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d9e222-c952-4e9f-b68b-7d23422395ff",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465c4236-a877-4dcc-b498-5cda9a895c69",
   "metadata": {},
   "source": [
    "## Analysis Part 1: SDoF-to-MDoF Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86200687-ccbf-4df0-bde2-7c4b3d20fbf1",
   "metadata": {},
   "source": [
    "#### The calibration function (calibrateModel) requires six input arguments:\n",
    "1. Number of storeys\n",
    "2. First-mode transformation factor (gamma)\n",
    "3. The capacity array of the single degree-of-freedom oscillator\n",
    "4. The fundamental period of the single degree-of-freedom oscillator\n",
    "5. Boolean flag whether the lateral load-resisting system for the considered building class is moment-resisting frames (or not)\n",
    "6. Boolean flag whether the building class expects a soft-storey mechanism to be activated (or not)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f37bde-c84e-40bd-8050-6c414d4c17c7",
   "metadata": {},
   "source": [
    "#### The calibration function (calibrate_model) from \"calibration\" returns four output variables:\n",
    "1. The floor mass array to be assigned to the MDOF model generator (floor_masses)\n",
    "2. The storey deformation (in m) capacity to be assigned to the MDOF model generator (storey_disps)\n",
    "3. The acceleration capacity (in g) to be assigned to the MDOF model generator (storey_forces)\n",
    "4. The considered mode shape (mdof_phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2098220-a7f0-4f5f-b369-f7adb4c759c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibrate the model using the Lu et al. (2016) method\n",
    "floor_masses, storey_disps, storey_forces, mdof_phi = calibrate_model(number_storeys, gamma, sdof_capacity, sdof_period, isFrame, isSOS)\n",
    "\n",
    "print('The mass of each floor (in tonnes):', floor_masses)\n",
    "print('The first-mode shape used for calibration:', mdof_phi)\n",
    "\n",
    "# Plot the capacities to visualise the outcome of the calibration\n",
    "for i in range(storey_disps.shape[0]):\n",
    "   plt.plot(np.concatenate(([0.0], storey_disps[i,:])), np.concatenate(([0.0], storey_forces[i,:]*9.81)), label = f'Storey #{i+1}')\n",
    "plt.plot(np.concatenate(([0.0], sdof_capacity[:,0])), np.concatenate(([0.0], sdof_capacity[:,1]*9.81)), label = f'SDOF Capacity')\n",
    "plt.xlabel('Storey Deformation [m]', fontsize= FONTSIZE_1)\n",
    "plt.ylabel('Storey Shear [kN]', fontsize = FONTSIZE_1)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.grid(visible=True, which='major')\n",
    "plt.grid(visible=True, which='minor')\n",
    "plt.xlim([0.00, 0.03])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26249fb-95f2-4d77-8ad7-d2fd38fc02f5",
   "metadata": {},
   "source": [
    "## Analysis Part 2: Setting Up Analysis and Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5bb079-a45c-4c96-b6da-ee01e6c7d168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise MDOF storage lists\n",
    "mdof_coll_index_list = []               # List for collapse index\n",
    "mdof_peak_disp_list  = []               # List for peak floor displacement (returns all peak values along the building height)\n",
    "mdof_peak_drift_list = []               # List for peak storey drift (returns all peak values along the building height)\n",
    "mdof_peak_accel_list = []               # List for peak floor acceleration (returns all peak values along the building height)\n",
    "mdof_max_peak_drift_list = []           # List for maximum peak storey drift (returns the maximum value) \n",
    "mdof_max_peak_drift_dir_list = []       # List for maximum peak storey drift directions\n",
    "mdof_max_peak_drift_loc_list = []       # List for maximum peak storey drift locations\n",
    "mdof_max_peak_accel_list = []           # List for maximum peak floor acceleration (returns the maximum value)\n",
    "mdof_max_peak_accel_dir_list = []       # List for maximum peak floor acceleration directions \n",
    "mdof_max_peak_accel_loc_list = []       # List for maximum peak floor acceleration locations \n",
    "\n",
    "# Define directory for temporary analysis outputs\n",
    "temp_nrha_outdir = f'{nlthaOutDir}/temp'\n",
    "if not os.path.exists(f'{temp_nrha_outdir}'):\n",
    "    os.makedirs(f'{temp_nrha_outdir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0790ae3d-e95c-46f8-8ccc-a2aee02444b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over ground-motion records, compile MDOF model and run NLTHA\n",
    "gmrs = sorted_alphanumeric(os.listdir(f'{gmDir}/acc'))                         # Sort the ground-motion records alphanumerically\n",
    "dts  = sorted_alphanumeric(os.listdir(f'{gmDir}/dts'))                         # Sort the ground-motion time-step files alphanumerically\n",
    "\n",
    "for i in range(len(gmrs)):\n",
    "    ### Print post-processing iteration\n",
    "    print('================================================================')\n",
    "    print('============== ANALYSING: {:d} out of {:d} =================='.format(i+1, len(gmrs)))\n",
    "    print('================================================================')\n",
    "\n",
    "    ### Compile the MDOF model    \n",
    "    model = modeller(number_storeys,floor_heights,floor_masses,storey_disps,storey_forces*units.g)    # Initialise the class (Build the model)\n",
    "    model.compile_model()                                                                              # Compile the MDOF model\n",
    "    if i==0:\n",
    "        model.plot_model()                                                                            # Visualise the model\n",
    "    model.do_gravity_analysis()                                                                       # Do gravity analysis\n",
    "\n",
    "    if number_storeys == 1:\n",
    "        num_modes = 1\n",
    "    else:\n",
    "        num_modes = 3\n",
    "    T, _ = model.do_modal_analysis(num_modes = num_modes)                                        # Do modal analysis and get period of vibration\n",
    "\n",
    "    ### Define ground motion objects\n",
    "    fnames = [f'{gmDir}/acc/gmr_{i}.csv']                                       # Ground-motion record names\n",
    "    fdts = f'{gmDir}/dts/dts_{i}.csv'                                           # Ground-motion time-step names \n",
    "    dt_gm = pd.read_csv(fdts)[pd.read_csv(fdts).columns[0]].loc[0]              # Ground-motion time-step\n",
    "    t_max = pd.read_csv(fdts)[pd.read_csv(fdts).columns[0]].iloc[-1]            # Ground-motion duration\n",
    "   \n",
    "    ### Define analysis params and do NLTHA\n",
    "    dt_ansys = dt_gm                                                            # Set the analysis time-step\n",
    "    sf = units.g                                                                # Set the scaling factor (if records are in g, a scaling factor of 9.81 m/s2 must be used to be consistent with opensees) \n",
    "    control_nodes, coll_index, peak_drift, peak_accel, max_peak_drift, max_peak_drift_dir, max_peak_drift_loc, max_peak_accel, max_peak_accel_dir, max_peak_accel_loc, peak_disp = model.do_nrha_analysis(fnames, \n",
    "                                                                                                                                                                                                          dt_gm, \n",
    "                                                                                                                                                                                                          sf, \n",
    "                                                                                                                                                                                                          t_max, \n",
    "                                                                                                                                                                                                          dt_ansys,\n",
    "                                                                                                                                                                                                          temp_nrha_outdir,\n",
    "                                                                                                                                                                                                          pflag=True,\n",
    "                                                                                                                                                                                                          xi = sdof_damping)\n",
    "\n",
    "    ### Store the analysis\n",
    "    mdof_coll_index_list.append(coll_index)\n",
    "    mdof_peak_drift_list.append(peak_drift)\n",
    "    mdof_peak_accel_list.append(peak_accel)\n",
    "    mdof_peak_disp_list.append(peak_disp)\n",
    "    mdof_max_peak_drift_list.append(max_peak_drift)\n",
    "    mdof_max_peak_drift_dir_list.append(max_peak_drift_dir)\n",
    "    mdof_max_peak_drift_loc_list.append(max_peak_drift_loc)\n",
    "    mdof_max_peak_accel_list.append(max_peak_accel)\n",
    "    mdof_max_peak_accel_dir_list.append(max_peak_accel_dir)\n",
    "    mdof_max_peak_accel_loc_list.append(max_peak_accel_loc)\n",
    "\n",
    "print('ANALYSIS COMPLETED')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb7370a-a06c-4390-ad5a-f3cdbf0a474e",
   "metadata": {},
   "source": [
    "## Analysis Part 3: Export The Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1581cba7-e25e-4614-8678-cdbd03123ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the analysis results in a dictionary\n",
    "ansys_dict = {}\n",
    "labels = ['T','control_nodes', 'mdof_coll_index_list',\n",
    "          'mdof_peak_drift_list','mdof_peak_accel_list',\n",
    "          'mdof_max_peak_drift_list', 'mdof_max_peak_drift_dir_list', \n",
    "          'mdof_max_peak_drift_loc_list','mdof_max_peak_accel_list',\n",
    "          'mdof_max_peak_accel_dir_list','mdof_max_peak_accel_loc_list',\n",
    "          'mdof_peak_disp_list']\n",
    "for i, label in enumerate(labels):\n",
    "    ansys_dict[label] = vars()[f'{label}']\n",
    "# Export the analysis output variable to a pickle file using the \"export_to_pkl\" function from \"utilities\"\n",
    "export_to_pkl(f'{nlthaOutDir}/ansys.pkl', ansys_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c597d643-c4a5-4794-85e7-f3bc29094f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()\n",
    "print('Elapsed Time:', (end - start)/60, 'minutes')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
